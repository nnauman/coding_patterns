{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Table Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A hash function for strings\n",
    "\n",
    "def string_hash(s, modulus):\n",
    "    MULT = 997\n",
    "    return functools.reduce(lambda v, c: (v * MULT + ord(c)) % modulus, s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_hash(\"tat\", 701)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're doing here is representing the string as a base MULT integer. We then take divide this integer by the modulus and take the remainder. This gives us an integer in the range [0, modulus-1] which is our hash value i.e. the \"slot\" in the array which the key (string) will be put into. Note that larger modulus takes more space but a smaller modulus may result in large number of collisions so this value must be chosen wisely. A large enough (but not too large) prime number is usually a good choice as it reduces the likelihood of a some pattern in the underlying data preventing uniform distribution of the keys (i.e. choosing a power of 2 is simply selecting the low order bits and could be prone to placing similar strings in the same bucket - bad!)\n",
    "\n",
    "Note that by taking the modulus at each step rather than at the very end, we still end up with the same number. This is because the end result without taking modulus is congruent to the end result where we do take the modulus at multiuplication/addition in the reduce function. Let us verify this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_hash2(s, modulus):\n",
    "    MULT = 997\n",
    "    hash_value = functools.reduce(lambda v, c: (v * MULT + ord(c)), s, 0)\n",
    "    hash_value %= modulus\n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_hash2(\"tat\", 701)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anagram groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['debitcard', 'elvis', 'silent', 'badcredit', 'lives', 'freedom', 'listen', 'levis', 'money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anagrams(l):\n",
    "    anagram_map = collections.defaultdict(list)\n",
    "    \n",
    "    for s in l:\n",
    "        anagram_map[''.join(sorted(s))].append(s)\n",
    "        \n",
    "    return [v for v in anagram_map.values() if len(v) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['debitcard', 'badcredit'], ['elvis', 'lives', 'levis'], ['silent', 'listen']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_anagrams(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contact:\n",
    "    \n",
    "    def __init__(self, names):\n",
    "        self.names = names # List of contacts\n",
    "        \n",
    "    def __hash__(self):\n",
    "        # Want to hash set of names so we must use frozenset. Repeats in the contact list do not matter\n",
    "        # order does not matter either. This makes the set data structure an ideal choice.\n",
    "        return hash(frozenset(self.names))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return set(self.names) == set(other.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_contact_lists(contacts):\n",
    "    return list(set(contacts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find smallest subarray covering all values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement: https://leetcode.com/problems/minimum-window-substring/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is the same as the one already done in the sliding window section. This is an alternative (but tighter) O(n) algorithm. Note that conceptually, this problem is very simple to solve in this way: for each character in t (the query), we keep track of the latest index seen. As soon as we have all len(t) characters accounted for, we simply take the latest index-the earliest index as a candidate.\n",
    "\n",
    "The sliding window tackles this by first skipping any extra query characters and contracts the window from the left. However, this is not needed IF we had a data structure the could O(1) retrieval of min, O(1) append, and O(1) removal of elements (at arbitrary positions). The last requirement makes it clear we need a linked list (the prev 2 could be implemented with other data structures like arrays or heaps). Here is a solution using a doubly linked list that keeps track of the order and finds the min in O(1) time (i.e. it is just the head of the list). The hash map is used for fast lookup and to store the word:node mapping, the linked list itself is used to keep the indices in sorted order (we just need the min to be at the head, the order of the others don't matter).\n",
    "\n",
    "**Note**: This solution assume a query string t to have only unique letters. I.e. \"ABC\" is a valid query string but \"AABC\" is not. More work is needed to deal with repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minWindow(s: str, t: str) -> str:\n",
    "\n",
    "    from collections import namedtuple\n",
    "    Substring = namedtuple(\"Substring\", (\"left\", \"right\"))\n",
    "    import math\n",
    "\n",
    "    class DoublyLinkedListNode:\n",
    "\n",
    "        def __init__(self, value=None):\n",
    "            self.next = self.prev = None\n",
    "            self.value = value\n",
    "\n",
    "\n",
    "    class DoublyLinkedList:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.head = self.tail = None\n",
    "            self._size = 0\n",
    "\n",
    "        # Override len as we'll need the size of the linkedlist to compare with        \n",
    "        def __len__(self):\n",
    "            return self._size\n",
    "\n",
    "        def append(self, value):\n",
    "            node = DoublyLinkedListNode(value)\n",
    "            node.prev = self.tail\n",
    "\n",
    "            if self.tail:\n",
    "                self.tail.next = node\n",
    "            else:\n",
    "                self.head = node\n",
    "            self.tail = node\n",
    "            self._size += 1\n",
    "\n",
    "        def remove(self, node):\n",
    "\n",
    "            if node.prev:\n",
    "                node.prev.next = node.next\n",
    "            else:\n",
    "                self.head = node.next\n",
    "\n",
    "            if node.next:\n",
    "                node.next.prev = node.prev\n",
    "            else:\n",
    "                self.tail = node.prev\n",
    "\n",
    "            node.next = None\n",
    "            node.prev = None\n",
    "\n",
    "            self._size -= 1\n",
    "\n",
    "\n",
    "    candidate_list = DoublyLinkedList()\n",
    "    candidate_dict = {c: None for c in t}\n",
    "    substring = Substring(left=-math.inf, right=math.inf)\n",
    "\n",
    "    for i, c in enumerate(s):\n",
    "\n",
    "        if c in candidate_dict:\n",
    "            prev_node = candidate_dict[c]\n",
    "            if prev_node:\n",
    "                candidate_list.remove(prev_node)\n",
    "            candidate_list.append(i)\n",
    "            candidate_dict[c] = candidate_list.tail\n",
    "\n",
    "        if len(candidate_list) == len(candidate_dict) \\\n",
    "                and (i-candidate_list.head.value) < (substring.right-substring.left):\n",
    "            substring = Substring(left=candidate_list.head.value, right=i)\n",
    "\n",
    "    return s[substring.left:substring.right+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"A\", \"A\", \"B\", \"E\", \"C\", \"A\", \"B\", \"C\"]\n",
    "t = [\"A\", \"B\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minWindow(s, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time and Space COmplexity**: Same as before the the O(n) time is now tighter. Before it was O(2n) but now its a tight O(1n). This makes this algorithm ideal for streaming situations as we don't need to keep track of previous elements after we've processed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Window Subsequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement: https://leetcode.com/problems/minimum-window-subsequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minWindow(self, S: str, T: str) -> str:\n",
    "\n",
    "    keyword_id_map = {c:i for i, c in enumerate(T)}\n",
    "\n",
    "    last_seen = [-1] * len(T)\n",
    "    dp = [float('inf')] * len(T)\n",
    "    min_len = float('inf')\n",
    "    ret_indices = (-1, -1)\n",
    "\n",
    "    for i, c in enumerate(S):\n",
    "        if c in keyword_id_map:\n",
    "            key_id = keyword_id_map[c]\n",
    "\n",
    "            if key_id == 0:\n",
    "                dp[key_id] = 1\n",
    "\n",
    "            else:\n",
    "                if dp[key_id-1] != float('inf'):\n",
    "                    distance = i - last_seen[key_id-1]\n",
    "                    dp[key_id] = dp[key_id-1] + distance\n",
    "\n",
    "            last_seen[key_id] = i\n",
    "\n",
    "            if key_id == len(T)-1 and dp[key_id] < min_len:\n",
    "                min_len = dp[key_id]\n",
    "                ret_indices = (i-min_len+1, i)          \n",
    "\n",
    "    return S[ret_indices[0]: ret_indices[1]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for only unique query strings, need to return to the more difficult version of duplicates allowed in query string...\n",
    "\n",
    "Time: O(n) where n is length of S.\n",
    "\n",
    "Space: O(3m) = O(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement: You have a file where each line is a student ID followed by a score they recieved. Return the student with the highest average score on their top 3 exams. The student must have at least 3 exams to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_scorer(file):\n",
    "    import collections\n",
    "    import heapq\n",
    "    \n",
    "    student_scores = collections.defaultdict(list)\n",
    "    \n",
    "    for row in file:\n",
    "        student_id, score = row.split()\n",
    "        \n",
    "        if len(student_scores[student_id]) < 3:\n",
    "            heapq.heappush(student_scores[student_id], int(score))\n",
    "        else:\n",
    "            heapq.heappushpop(student_scores[student_id], int(score))\n",
    "        \n",
    "    # Note that the top average score is the same as the sum of the scores since all valid students are\n",
    "    # required to have the same number of scores (3)\n",
    "    top_scores = [(name, sum(scores)) for name, scores in student_scores.items() if len(scores)==3]\n",
    "    return max(top_scores, key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [\n",
    "    \"1 85\",\n",
    "    \"1 70\",\n",
    "    \"2 92\",\n",
    "    \"3 91\",\n",
    "    \"2 44\",\n",
    "    \"2 61\",\n",
    "    \"3 44\",\n",
    "    \"3 21\",\n",
    "    \"1 100\",\n",
    "    \"4 100\",\n",
    "    \"4 100\",\n",
    "    \"5 105\",\n",
    "]\n",
    "\n",
    "# Should return student 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_scorer(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is fairly straightforwad. We're just performing a groupby and keeping track of the top 3 scores per student via a min heap. After this calculation is complete, we calculate the sum and return the student with the highest sum (making sure that all students considered have exactly 3 scores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**time**: O(n) where n is the number of entries in the file\n",
    "\n",
    "**space**: O(m) where m is the number of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
